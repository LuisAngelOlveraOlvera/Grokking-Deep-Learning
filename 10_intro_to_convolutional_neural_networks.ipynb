{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisAngelOlveraOlvera/Grokking-Deep-Learning/blob/main/10_intro_to_convolutional_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBich5vDytaq",
        "outputId": "1343fe95-04c9-4a67-ea8f-da747a0d056f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels:  [[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "test_labels:  [[0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "hidden_size:  10000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Configuración inicial  y carga de datos\n",
        "np.random.seed(1)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "images, labels = (x_train[0:1000].reshape(1000, 28*28)/255, y_train[0:1000])\n",
        "test_images = x_test.reshape(len(x_test), 28*28) / 255\n",
        "test_labels = y_test\n",
        "\n",
        "# Conversión de etiquetas a one-hot encoding\n",
        "one_hot_labels = np.zeros((len(labels), 10))\n",
        "\n",
        "for i, l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "print(\"labels: \", labels)\n",
        "\n",
        "test_one_hot_labels = np.zeros((len(test_labels), 10))\n",
        "\n",
        "for i, l in enumerate(test_labels):\n",
        "  test_one_hot_labels[i][l] = 1\n",
        "test_labels = test_one_hot_labels\n",
        "\n",
        "print(\"test_labels: \", test_labels)\n",
        "\n",
        "# Funciones de activación\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh2deriv(output):\n",
        "    return 1 - (output ** 2)\n",
        "\n",
        "def softmax(x):\n",
        "    temp = np.exp(x)\n",
        "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
        "\n",
        "# Inicialización de parámetros\n",
        "alpha, iterations = (2, 300)\n",
        "pixels_per_image, num_labels = (784, 10)\n",
        "batch_size = 128\n",
        "input_rows, input_cols = (28, 28)\n",
        "kernel_rows, kernel_cols = (3, 3)\n",
        "num_kernels = 16\n",
        "hidden_size = ((input_rows - kernel_rows) * (input_cols - kernel_cols)) * num_kernels\n",
        "print(\"hidden_size: \", hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbkt0RRczkIA",
        "outputId": "34439374-9a43-424d-fc82-2e407899de8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kernels:  [[ 1.70328231e-03 -5.97770204e-03 -1.72637459e-03  7.66328068e-03\n",
            "   3.02881408e-03  8.56675338e-03  5.51296256e-04  3.26438096e-03\n",
            "   4.90987642e-04  7.06176896e-03 -5.62288802e-03 -2.75093130e-03\n",
            "   2.78062110e-03 -6.44540395e-03 -7.59203775e-03  4.98202336e-03]\n",
            " [ 3.41203030e-03 -8.69349186e-03  1.01748480e-03  2.05430893e-03\n",
            "  -6.95127390e-03 -4.41626201e-03 -1.62584550e-03  6.42637849e-03\n",
            "  -5.60240168e-03  2.71610574e-04 -8.04507054e-03  6.20940038e-03\n",
            "   3.25843127e-03 -1.78213333e-03  6.01667078e-03  6.30671014e-03]\n",
            " [-8.35596746e-03 -5.04125968e-03 -3.67738299e-03 -9.18998871e-03\n",
            "  -8.00852519e-03 -9.48393207e-03 -8.37650939e-03  4.37158386e-03\n",
            "   2.43512431e-03 -8.03564237e-03 -5.38022960e-03  4.67030246e-04\n",
            "  -2.71828310e-03  3.09839204e-03 -9.17337467e-03  5.64183692e-03]\n",
            " [-4.82516555e-03 -7.70515482e-03 -9.57758920e-03 -2.57027131e-03\n",
            "   3.40429098e-03  7.38807194e-03  8.30585381e-03 -3.85651706e-03\n",
            "   6.85507543e-03 -3.49562910e-04  8.08055344e-03 -3.33690190e-03\n",
            "  -1.38339592e-03 -8.36526620e-03 -6.77734919e-03  3.00846008e-03]\n",
            " [-4.74428583e-03  7.58439314e-03  8.44239887e-03  1.53546855e-03\n",
            "   9.97722055e-03  4.59628148e-03  7.35139878e-03 -1.69412464e-03\n",
            "   5.61955355e-03 -6.12187117e-05  4.23610660e-03  5.37978812e-03\n",
            "  -5.11717835e-03 -8.00346398e-03 -4.63720609e-03  1.47362211e-03]\n",
            " [-3.01019228e-03  2.07626542e-03 -3.38963068e-03 -3.93254392e-03\n",
            "   8.31505491e-03  8.16740590e-05 -5.57325259e-03 -3.08226744e-03\n",
            "   9.62505178e-03  2.35660108e-03  1.20519898e-03 -9.03790575e-03\n",
            "   1.29177262e-03 -9.14135638e-03  8.48295777e-03 -7.79186912e-03]\n",
            " [ 7.37570916e-03  1.48718203e-03  7.95251299e-03  5.66335473e-03\n",
            "  -4.88742380e-03  7.30926272e-03 -2.89759202e-04 -3.81427786e-03\n",
            "   9.46519697e-03 -6.12865237e-03  9.81029332e-03 -7.81336011e-05\n",
            "   1.84229872e-03 -5.67140374e-03 -2.69462711e-04  3.48407102e-03]\n",
            " [ 1.55498367e-03 -9.62830557e-03  8.98403310e-03  8.27154403e-04\n",
            "  -6.47162013e-03  7.29046193e-03 -6.48854032e-03 -7.50066807e-03\n",
            "   3.40542087e-03 -9.26836174e-03 -7.98654093e-03 -2.93955648e-03\n",
            "  -8.87765475e-03 -3.50815713e-03 -7.63613282e-03 -3.38043146e-03]\n",
            " [-4.02930021e-04 -3.47429299e-03  9.01014652e-03  2.58820628e-03\n",
            "  -5.58610897e-03 -5.07332945e-03  1.40941340e-05  1.68733179e-03\n",
            "   5.48656082e-03  2.06336492e-03  9.85083654e-03  5.39706055e-03\n",
            "  -3.89265245e-03  3.98226750e-03 -3.15470315e-03 -8.53102769e-03]]\n",
            "weights_1_2:  [[-0.07389044 -0.06363693 -0.04519038 ...  0.05021839 -0.01732678\n",
            "  -0.05730014]\n",
            " [-0.06017208 -0.01857008 -0.00597221 ...  0.02638777  0.05463793\n",
            "  -0.02200394]\n",
            " [ 0.08824964 -0.05784412  0.09699264 ... -0.09726002 -0.07002328\n",
            "  -0.07578172]\n",
            " ...\n",
            " [ 0.05915732 -0.06023406  0.04947417 ...  0.07651996 -0.06029912\n",
            "  -0.06130734]\n",
            " [ 0.09189814  0.02513429 -0.01738997 ... -0.04811251  0.01989486\n",
            "   0.02290061]\n",
            " [-0.09575357  0.01522006  0.0315828  ...  0.08397891  0.03399961\n",
            "   0.04887987]]\n"
          ]
        }
      ],
      "source": [
        "kernels = 0.02 * np.random.random((kernel_rows * kernel_cols, num_kernels))- 0.01\n",
        "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels))-0.1\n",
        "print(\"kernels: \", kernels)\n",
        "print(\"weights_1_2: \", weights_1_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1XZjx_v4HtM",
        "outputId": "3283ea11-b210-48ef-b177-6adaebfbdbda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 0 Test Accuracy: 0.8738 Train Accuracy: 0.802\n",
            "\n",
            "Iteration: 1 Test Accuracy: 0.8773 Train Accuracy: 0.824\n",
            "\n",
            "Iteration: 2 Test Accuracy: 0.8793 Train Accuracy: 0.807\n",
            "\n",
            "Iteration: 3 Test Accuracy: 0.8772 Train Accuracy: 0.812\n",
            "\n",
            "Iteration: 4 Test Accuracy: 0.8787 Train Accuracy: 0.817\n",
            "\n",
            "Iteration: 5 Test Accuracy: 0.8757 Train Accuracy: 0.812\n",
            "\n",
            "Iteration: 6 Test Accuracy: 0.8771 Train Accuracy: 0.826\n",
            "\n",
            "Iteration: 7 Test Accuracy: 0.8766 Train Accuracy: 0.822\n",
            "\n",
            "Iteration: 8 Test Accuracy: 0.8777 Train Accuracy: 0.806\n",
            "\n",
            "Iteration: 9 Test Accuracy: 0.878 Train Accuracy: 0.812\n",
            "\n",
            "Iteration: 10 Test Accuracy: 0.8777 Train Accuracy: 0.821\n",
            "\n",
            "Iteration: 11 Test Accuracy: 0.8782 Train Accuracy: 0.806\n",
            "\n",
            "Iteration: 12 Test Accuracy: 0.8784 Train Accuracy: 0.813\n",
            "\n",
            "Iteration: 13 Test Accuracy: 0.8784 Train Accuracy: 0.816\n",
            "\n",
            "Iteration: 14 Test Accuracy: 0.8773 Train Accuracy: 0.826\n",
            "\n",
            "Iteration: 15 Test Accuracy: 0.879 Train Accuracy: 0.815\n",
            "\n",
            "Iteration: 16 Test Accuracy: 0.8774 Train Accuracy: 0.811\n",
            "\n",
            "Iteration: 17 Test Accuracy: 0.8767 Train Accuracy: 0.814\n",
            "\n",
            "Iteration: 18 Test Accuracy: 0.8768 Train Accuracy: 0.829\n",
            "\n",
            "Iteration: 19 Test Accuracy: 0.8768 Train Accuracy: 0.819\n",
            "\n",
            "Iteration: 20 Test Accuracy: 0.8763 Train Accuracy: 0.827\n",
            "\n",
            "Iteration: 21 Test Accuracy: 0.8775 Train Accuracy: 0.812\n",
            "\n",
            "Iteration: 22 Test Accuracy: 0.8762 Train Accuracy: 0.828\n",
            "\n",
            "Iteration: 23 Test Accuracy: 0.8772 Train Accuracy: 0.819\n",
            "\n",
            "Iteration: 24 Test Accuracy: 0.8774 Train Accuracy: 0.827\n",
            "\n",
            "Iteration: 25 Test Accuracy: 0.8792 Train Accuracy: 0.826\n",
            "\n",
            "Iteration: 26 Test Accuracy: 0.8809 Train Accuracy: 0.824\n",
            "\n",
            "Iteration: 27 Test Accuracy: 0.88 Train Accuracy: 0.804\n",
            "\n",
            "Iteration: 28 Test Accuracy: 0.8809 Train Accuracy: 0.808\n",
            "\n",
            "Iteration: 29 Test Accuracy: 0.8782 Train Accuracy: 0.814\n",
            "\n",
            "Iteration: 30 Test Accuracy: 0.88 Train Accuracy: 0.819\n",
            "\n",
            "Iteration: 31 Test Accuracy: 0.8794 Train Accuracy: 0.825\n",
            "\n",
            "Iteration: 32 Test Accuracy: 0.878 Train Accuracy: 0.831\n",
            "\n",
            "Iteration: 33 Test Accuracy: 0.8763 Train Accuracy: 0.826\n",
            "\n",
            "Iteration: 34 Test Accuracy: 0.8755 Train Accuracy: 0.825\n",
            "\n",
            "Iteration: 35 Test Accuracy: 0.8754 Train Accuracy: 0.824\n",
            "\n",
            "Iteration: 36 Test Accuracy: 0.8746 Train Accuracy: 0.808\n",
            "\n",
            "Iteration: 37 Test Accuracy: 0.873 Train Accuracy: 0.816\n",
            "\n",
            "Iteration: 38 Test Accuracy: 0.8725 Train Accuracy: 0.828\n",
            "\n",
            "Iteration: 39 Test Accuracy: 0.8782 Train Accuracy: 0.82\n",
            "\n",
            "Iteration: 40 Test Accuracy: 0.8777 Train Accuracy: 0.831\n",
            "\n",
            "Iteration: 41 Test Accuracy: 0.876 Train Accuracy: 0.82\n",
            "\n",
            "Iteration: 42 Test Accuracy: 0.8748 Train Accuracy: 0.814\n",
            "\n",
            "Iteration: 43 Test Accuracy: 0.8777 Train Accuracy: 0.808\n",
            "\n",
            "Iteration: 44 Test Accuracy: 0.8772 Train Accuracy: 0.817\n",
            "\n",
            "Iteration: 45 Test Accuracy: 0.8743 Train Accuracy: 0.824\n",
            "\n",
            "Iteration: 46 Test Accuracy: 0.8752 Train Accuracy: 0.824\n",
            "\n",
            "Iteration: 47 Test Accuracy: 0.8772 Train Accuracy: 0.82\n",
            "\n",
            "Iteration: 48 Test Accuracy: 0.8745 Train Accuracy: 0.812\n",
            "\n",
            "Iteration: 49 Test Accuracy: 0.8761 Train Accuracy: 0.82\n",
            "\n",
            "Iteration: 50 Test Accuracy: 0.8751 Train Accuracy: 0.818\n",
            "\n",
            "Iteration: 51 Test Accuracy: 0.8759 Train Accuracy: 0.823\n",
            "\n",
            "Iteration: 52 Test Accuracy: 0.8746 Train Accuracy: 0.818\n",
            "\n",
            "Iteration: 53 Test Accuracy: 0.8767 Train Accuracy: 0.813\n",
            "\n",
            "Iteration: 54 Test Accuracy: 0.8767 Train Accuracy: 0.839\n",
            "\n",
            "Iteration: 55 Test Accuracy: 0.8782 Train Accuracy: 0.822\n",
            "\n",
            "Iteration: 56 Test Accuracy: 0.8776 Train Accuracy: 0.824\n",
            "\n",
            "Iteration: 57 Test Accuracy: 0.8786 Train Accuracy: 0.833\n",
            "\n",
            "Iteration: 58 Test Accuracy: 0.8789 Train Accuracy: 0.821\n",
            "\n",
            "Iteration: 59 Test Accuracy: 0.8777 Train Accuracy: 0.82\n",
            "\n",
            "Iteration: 60 Test Accuracy: 0.8769 Train Accuracy: 0.822\n",
            "\n",
            "Iteration: 61 Test Accuracy: 0.8782 Train Accuracy: 0.833\n",
            "\n",
            "Iteration: 62 Test Accuracy: 0.8748 Train Accuracy: 0.825\n",
            "\n",
            "Iteration: 63 Test Accuracy: 0.8759 Train Accuracy: 0.818\n",
            "\n",
            "Iteration: 64 Test Accuracy: 0.8771 Train Accuracy: 0.809\n",
            "\n",
            "Iteration: 65 Test Accuracy: 0.8758 Train Accuracy: 0.82\n",
            "\n",
            "Iteration: 66 Test Accuracy: 0.8762 Train Accuracy: 0.816\n",
            "\n",
            "Iteration: 67 Test Accuracy: 0.8788 Train Accuracy: 0.832\n",
            "\n",
            "Iteration: 68 Test Accuracy: 0.8769 Train Accuracy: 0.83\n",
            "\n",
            "Iteration: 69 Test Accuracy: 0.8739 Train Accuracy: 0.817\n",
            "\n",
            "Iteration: 70 Test Accuracy: 0.8767 Train Accuracy: 0.833\n",
            "\n",
            "Iteration: 71 Test Accuracy: 0.8764 Train Accuracy: 0.828\n",
            "\n",
            "Iteration: 72 Test Accuracy: 0.8752 Train Accuracy: 0.842\n",
            "\n",
            "Iteration: 73 Test Accuracy: 0.8771 Train Accuracy: 0.826\n",
            "\n",
            "Iteration: 74 Test Accuracy: 0.8742 Train Accuracy: 0.828\n",
            "\n",
            "Iteration: 75 Test Accuracy: 0.877 Train Accuracy: 0.822\n",
            "\n",
            "Iteration: 76 Test Accuracy: 0.8764 Train Accuracy: 0.831\n",
            "\n",
            "Iteration: 77 Test Accuracy: 0.8753 Train Accuracy: 0.822\n",
            "\n",
            "Iteration: 78 Test Accuracy: 0.8767 Train Accuracy: 0.837\n",
            "\n",
            "Iteration: 79 Test Accuracy: 0.8752 Train Accuracy: 0.832\n",
            "\n",
            "Iteration: 80 Test Accuracy: 0.8766 Train Accuracy: 0.834\n",
            "\n",
            "Iteration: 81 Test Accuracy: 0.8754 Train Accuracy: 0.831\n",
            "\n",
            "Iteration: 82 Test Accuracy: 0.8759 Train Accuracy: 0.826\n",
            "\n",
            "Iteration: 83 Test Accuracy: 0.8751 Train Accuracy: 0.828\n",
            "\n",
            "Iteration: 84 Test Accuracy: 0.8766 Train Accuracy: 0.831\n",
            "\n",
            "Iteration: 85 Test Accuracy: 0.8744 Train Accuracy: 0.819\n",
            "\n",
            "Iteration: 86 Test Accuracy: 0.8758 Train Accuracy: 0.833\n",
            "\n",
            "Iteration: 87 Test Accuracy: 0.8734 Train Accuracy: 0.835\n",
            "\n",
            "Iteration: 88 Test Accuracy: 0.8745 Train Accuracy: 0.823\n",
            "\n",
            "Iteration: 89 Test Accuracy: 0.8743 Train Accuracy: 0.831\n",
            "\n",
            "Iteration: 90 Test Accuracy: 0.8751 Train Accuracy: 0.829\n",
            "\n",
            "Iteration: 91 Test Accuracy: 0.8753 Train Accuracy: 0.838\n",
            "\n",
            "Iteration: 92 Test Accuracy: 0.8768 Train Accuracy: 0.832\n",
            "\n",
            "Iteration: 93 Test Accuracy: 0.8737 Train Accuracy: 0.825\n",
            "\n",
            "Iteration: 94 Test Accuracy: 0.8761 Train Accuracy: 0.823\n",
            "\n",
            "Iteration: 95 Test Accuracy: 0.8778 Train Accuracy: 0.826\n",
            "\n",
            "Iteration: 96 Test Accuracy: 0.8747 Train Accuracy: 0.842\n"
          ]
        }
      ],
      "source": [
        "# función para extraer secciones de la imagen\n",
        "def get_image_section(layer, row_from, row_to, col_from, col_to):\n",
        "  sub_section = layer[:, row_from:row_to, col_from:col_to]\n",
        "  return sub_section.reshape(-1,1, row_to - row_from, col_to - col_from)\n",
        "\n",
        "# entrenamiento del modelo\n",
        "for j in range(iterations):\n",
        "    correct_cnt = 0\n",
        "    for i in range(int(len(images) / batch_size)):\n",
        "        batch_start, batch_end = (i * batch_size, (i + 1) * batch_size)\n",
        "        layer_0 = images[batch_start:batch_end].reshape(batch_size, input_rows, input_cols)\n",
        "\n",
        "        sects = []\n",
        "        for row_start in range(layer_0.shape[1] - kernel_rows):\n",
        "            for col_start in range(layer_0.shape[2] - kernel_cols):\n",
        "                sect = get_image_section(layer_0, row_start, row_start + kernel_rows, col_start, col_start + kernel_cols)\n",
        "                sects.append(sect)\n",
        "\n",
        "        expanded_input = np.concatenate(sects, axis=1)\n",
        "        es = expanded_input.shape\n",
        "        flattened_input = expanded_input.reshape(es[0]*es[1],-1)\n",
        "\n",
        "        kernel_output = flattened_input.dot(kernels)\n",
        "        layer_1 = tanh(kernel_output.reshape(es[0],-1))\n",
        "\n",
        "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "        layer_1 *= dropout_mask *2\n",
        "\n",
        "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
        "\n",
        "        for k in range(batch_size):\n",
        "          labelset = labels[batch_start + k:batch_start + k+1]\n",
        "          correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labelset))\n",
        "\n",
        "        layer_2_delta = (labels[batch_start:batch_end] - layer_2) / (batch_size * layer_2.shape[0])\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1)\n",
        "        layer_1_delta *= dropout_mask\n",
        "\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        l1d_reshape = layer_1_delta.reshape(kernel_output.shape)\n",
        "        k_update = flattened_input.T.dot(l1d_reshape)\n",
        "        kernels -= alpha * k_update\n",
        "\n",
        "# Prueba del modelo\n",
        "    # Prueba del modelo\n",
        "    test_correct_cnt = 0\n",
        "    for i in range(len(test_images)):\n",
        "        layer_0 = test_images[i:i+1].reshape(1, 28, 28)\n",
        "\n",
        "        sects = []\n",
        "        for row_start in range(layer_0.shape[1] - kernel_rows):\n",
        "            for col_start in range(layer_0.shape[2] - kernel_cols):\n",
        "                sect = get_image_section(layer_0, row_start, row_start + kernel_rows, col_start, col_start + kernel_cols)\n",
        "                sects.append(sect)\n",
        "\n",
        "        expanded_input = np.concatenate(sects, axis=1)\n",
        "        es = expanded_input.shape\n",
        "        flattened_input = expanded_input.reshape(es[0] * es[1], -1)\n",
        "\n",
        "        kernel_output = flattened_input.dot(kernels)\n",
        "        layer_1 = tanh(kernel_output.reshape(es[0], -1))\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "\n",
        "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "\n",
        "    if j % 1 == 0:\n",
        "        print(\"\\nIteration:\", j,\n",
        "              \"Test Accuracy:\", test_correct_cnt / float(len(test_images)),\n",
        "              \"Train Accuracy:\", correct_cnt / float(len(images)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "nvhct8iU9zbg",
        "outputId": "a44e96a9-cbbe-499e-a4d4-dfabfa00864e"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-20-65760a705e61>, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-65760a705e61>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    test_correct_cnt = 0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFR/LdITrmvXRib0UsUlfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}